{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Project: Quora Insincere Question Classifier**\n---","metadata":{}},{"cell_type":"markdown","source":"# **Introduction** \n--- \n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Background: ","metadata":{}},{"cell_type":"markdown","source":"In today's digital age, social platforms have become hubs for information sharing and community engagement. Quora, one such platform, provides users with a platform to ask questions and receive answers from a diverse community. However, as with any open forum, there is a potential for misuse, where users may pose insincere or deceptive questions.\n\nThe classification of insincere questions is a significant challenge in natural language processing (NLP). It requires the ability to discern the underlying intent and identify questions that may be misleading, inflammatory, or offensive. Accurately detecting and categorizing these insincere questions is crucial to maintaining the quality and credibility of a platform like Quora.\n\nIn this project, we delve into the task of insincere question classification on Quora, using machine learning and NLP techniques. Our objective is to develop a robust and efficient model that can automatically differentiate between sincere and insincere questions.","metadata":{}},{"cell_type":"markdown","source":"## Dataset:","metadata":{}},{"cell_type":"markdown","source":"For our insincerity quest, we will leverage the Quora Insincere Questions Classification dataset, which is publicly available on Kaggle. This dataset comprises a large collection of questions from Quora, along with corresponding labels indicating whether each question is sincere or insincere. The dataset is annotated by human reviewers, providing valuable ground truth for training and evaluation purposes.\n\nOur dataset are divided into training and testing dataset.The data contains the following columns: \n\n1. **qid**: This is a unique number for each of the question in our datasets. \n2. **question_text**: The full text of a Quora question. \n3. **target**: The label encoding on whether a question is sincere or not. ","metadata":{}},{"cell_type":"markdown","source":"## Approachs: ","metadata":{}},{"cell_type":"markdown","source":"To tackle this problem, we will adopt a supervised learning approach. We will explore various NLP techniques to build a classification model that can effectively distinguish between sincere and insincere questions. This will involve several key steps:\n\n1. Data Collection: The Quora Insincere Questions Classification dataset is collected and downloaded from Kaggle. The dataset will be imported and processed using Google Colab. The data structures and features will be explored to gain a better understanding of the dataset.\n\n2. Data Preprocessing: Text data is preprocessed by tokenization, lowercasing, and removal of stop words and punctuation. Techniques like stemming or lemmatization may be applied for further normalization.\n\n3. Feature Extraction: The preprocessed text data will be transformed into numerical representations suitable for machine learning algorithms. For this project, we will be using word embeddings, such as Word2Vec or GloVe, to convert the text into dense vector representations that capture semantic relationships between words.\n\n4. Model Selection and Training: For this project, we will explore various NLP models suitable for insincere question classification, such as recurrent neural networks (RNNs), convolutional neural networks (CNNs), or transformer models like BERT. These models have shown promising results in NLP tasks and can capture complex patterns and dependencies in text data. We will select the most appropriate model based on its performance on the validation dataset and train it using the labeled training dataset.\n\n5. Model Evaluation: The trained NLP model will be evaluated using appropriate evaluation metrics, such as accuracy, precision, recall, and F1-score. The performance of the model will be assessed on the test dataset.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Importing Packages:","metadata":{}},{"cell_type":"code","source":"# Data manipution packages. \nimport pandas as pd\nimport numpy as np\n\n# Data visualization packages.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# File manager packages.\nimport os\nimport shutil\nfrom zipfile import ZipFile\n\n# Tensoflow packages.\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Flatten, Conv1D, MaxPooling1D, Bidirectional, LSTM, RNN, GRU, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential, Model\n\n# Other packages.\n%matplotlib inline","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-05-24T13:43:10.570146Z","iopub.execute_input":"2023-05-24T13:43:10.570721Z","iopub.status.idle":"2023-05-24T13:43:10.582346Z","shell.execute_reply.started":"2023-05-24T13:43:10.570676Z","shell.execute_reply":"2023-05-24T13:43:10.580989Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# **Data Collecion**\n---","metadata":{}},{"cell_type":"markdown","source":"For this project we will be working from the kaggle notebook,and since our data is already in our working station we would just be loading our dataset from the kaggle input directory. \n\nTo download this dataset from kaggle for colab and local system use, i will be providing commented code to help with this.","metadata":{}},{"cell_type":"markdown","source":"## Download kaggle dataset:","metadata":{}},{"cell_type":"markdown","source":"This commented code below is only for colab notebooks.","metadata":{}},{"cell_type":"code","source":"# Install kaggle api with Pip. \n# !pip install kaggle\n\n# # Uploading Kaggle api token key.\n# from google.colab import files\n\n# files.upload()\n\n# # Changing api token location.\n# !mkdir ~/.kaggle\n\n# !cp kaggle.json ~/.kaggle/\n\n# # set the appropriate permissions \n# !chmod 600 ~/.kaggle/kaggle.json\n\n# # verify api key.\n# !kaggle datasets list\n\n\n# # Downloading dataset. \n# !kaggle datasets download -d {dataset_name}\n\n# # Unzip folder. \n# ! unzip cards-image-datasetclassification.zip -d 1.Dataset.","metadata":{"execution":{"iopub.status.busy":"2023-05-24T13:11:32.229951Z","iopub.execute_input":"2023-05-24T13:11:32.230471Z","iopub.status.idle":"2023-05-24T13:11:32.236433Z","shell.execute_reply.started":"2023-05-24T13:11:32.230436Z","shell.execute_reply":"2023-05-24T13:11:32.235332Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Loading Dataset:","metadata":{}},{"cell_type":"markdown","source":"We will be importing and loading our training, and validation dataset.","metadata":{}},{"cell_type":"code","source":"# Checking input folder. \n\n## Defining a path exploral function. \n\ndef path_exploral(dir_path:str): \n    for dirname, _, filenames in os.walk(dir_path):\n        print(f\"Directory name: {dirname}\")\n        print(f\"File name: {filenames}\\n\\n\")\n    \n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n## Checking the input folder. \ninput_dir = '/kaggle/input'\n\npath_exploral(input_dir)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-24T13:30:51.929163Z","iopub.execute_input":"2023-05-24T13:30:51.929665Z","iopub.status.idle":"2023-05-24T13:30:51.940238Z","shell.execute_reply.started":"2023-05-24T13:30:51.929629Z","shell.execute_reply":"2023-05-24T13:30:51.939030Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Directory name: /kaggle/input\nFile name: []\n\n\nDirectory name: /kaggle/input/quora-insincere-questions-classification\nFile name: ['sample_submission.csv', 'embeddings.zip', 'train.csv', 'test.csv']\n\n\n/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n/kaggle/input/quora-insincere-questions-classification/train.csv\n/kaggle/input/quora-insincere-questions-classification/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extracting all files from kaggle/input \n\n## File path.\ninput_dir = '/kaggle/input/quora-insincere-questions-classification'\nworking_dir = '/kaggle/working'\n\n## Get the list of files \nfile_list = os.listdir(input_dir)\n\n## Copy each file from the source directory to the destination directory\nfor file in file_list:\n    source_file = os.path.join(input_dir, file)\n    destination_file = os.path.join(working_dir, file)\n    shutil.copy(source_file, destination_file)\n\n## Checking working dir.\npath_exploral(working_dir)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T14:00:19.643805Z","iopub.execute_input":"2023-05-24T14:00:19.644354Z","iopub.status.idle":"2023-05-24T14:02:24.201705Z","shell.execute_reply.started":"2023-05-24T14:00:19.644314Z","shell.execute_reply":"2023-05-24T14:02:24.199623Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Directory name: /kaggle/working\nFile name: ['embeddings.zip', '__notebook_source__.ipynb', 'train.csv', 'test.csv', 'sample_submission.csv']\n\n\n/kaggle/working/embeddings.zip\n/kaggle/working/__notebook_source__.ipynb\n/kaggle/working/train.csv\n/kaggle/working/test.csv\n/kaggle/working/sample_submission.csv\nDirectory name: /kaggle/working/.virtual_documents\nFile name: []\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data directory. \ndata_dir = os.path.join(working_dir)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T14:06:20.814353Z","iopub.execute_input":"2023-05-24T14:06:20.815341Z","iopub.status.idle":"2023-05-24T14:06:20.821052Z","shell.execute_reply.started":"2023-05-24T14:06:20.815288Z","shell.execute_reply":"2023-05-24T14:06:20.819700Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Unzipping Embedding file. \n\n## Embeddings directory.\nemb_zip_dir = os.path.join(data_dir,'embeddings.zip' )\n\n## Extracting all file\nwith ZipFile(emb_zip_dir) as zip_dir:\n    zip_dir.extractall(data_dir)\n\n## Checking input folder on updated files.\npath_exploral(working_dir)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T14:06:23.095876Z","iopub.execute_input":"2023-05-24T14:06:23.096336Z","iopub.status.idle":"2023-05-24T14:08:35.018616Z","shell.execute_reply.started":"2023-05-24T14:06:23.096304Z","shell.execute_reply":"2023-05-24T14:08:35.016989Z"},"trusted":true},"execution_count":30,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## Extracting all file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ZipFile(emb_zip_dir) \u001b[38;5;28;01mas\u001b[39;00m zip_dir:\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mzip_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m## Checking input folder on updated files.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m path_exploral(working_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1645\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[0;32m-> 1645\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1700\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(member, pwd\u001b[38;5;241m=\u001b[39mpwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[1;32m   1699\u001b[0m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[0;32m-> 1700\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:198\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buf:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"],"ename":"OSError","evalue":"[Errno 28] No space left on device","output_type":"error"}]}]}