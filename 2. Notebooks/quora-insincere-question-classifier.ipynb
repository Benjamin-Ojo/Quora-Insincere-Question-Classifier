{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Project: Quora Insincere Question Classifier**\n---","metadata":{}},{"cell_type":"markdown","source":"# **Introduction** \n--- \n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Background: ","metadata":{}},{"cell_type":"markdown","source":"In today's digital age, social platforms have become hubs for information sharing and community engagement. Quora, one such platform, provides users with a platform to ask questions and receive answers from a diverse community. However, as with any open forum, there is a potential for misuse, where users may pose insincere or deceptive questions.\n\nThe classification of insincere questions is a significant challenge in natural language processing (NLP). It requires the ability to discern the underlying intent and identify questions that may be misleading, inflammatory, or offensive. Accurately detecting and categorizing these insincere questions is crucial to maintaining the quality and credibility of a platform like Quora.\n\nIn this project, we delve into the task of insincere question classification on Quora, using machine learning and NLP techniques. Our objective is to develop a robust and efficient model that can automatically differentiate between sincere and insincere questions.","metadata":{}},{"cell_type":"markdown","source":"## Dataset:","metadata":{}},{"cell_type":"markdown","source":"For our insincerity quest, we will leverage the Quora Insincere Questions Classification dataset, which is publicly available on Kaggle. This dataset comprises a large collection of questions from Quora, along with corresponding labels indicating whether each question is sincere or insincere. The dataset is annotated by human reviewers, providing valuable ground truth for training and evaluation purposes.\n\nOur dataset are divided into training and testing dataset.The data contains the following columns: \n\n1. **qid**: This is a unique number for each of the question in our datasets. \n2. **question_text**: The full text of a Quora question. \n3. **target**: The label encoding on whether a question is sincere or not. ","metadata":{}},{"cell_type":"markdown","source":"## Approachs: ","metadata":{}},{"cell_type":"markdown","source":"To tackle this problem, we will adopt a supervised learning approach. We will explore various NLP techniques to build a classification model that can effectively distinguish between sincere and insincere questions. This will involve several key steps:\n\n1. Data Collection: The Quora Insincere Questions Classification dataset is collected and downloaded from Kaggle. The dataset will be imported and processed using Google Colab. The data structures and features will be explored to gain a better understanding of the dataset.\n\n2. Data Preprocessing: Text data is preprocessed by tokenization, lowercasing, and removal of stop words and punctuation. Techniques like stemming or lemmatization may be applied for further normalization.\n\n3. Feature Extraction: The preprocessed text data will be transformed into numerical representations suitable for machine learning algorithms. For this project, we will be using word embeddings, such as Word2Vec or GloVe, to convert the text into dense vector representations that capture semantic relationships between words.\n\n4. Model Selection and Training: For this project, we will explore various NLP models suitable for insincere question classification, such as recurrent neural networks (RNNs), convolutional neural networks (CNNs), or transformer models like BERT. These models have shown promising results in NLP tasks and can capture complex patterns and dependencies in text data. We will select the most appropriate model based on its performance on the validation dataset and train it using the labeled training dataset.\n\n5. Model Evaluation: The trained NLP model will be evaluated using appropriate evaluation metrics, such as accuracy, precision, recall, and F1-score. The performance of the model will be assessed on the test dataset.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Importing Packages:","metadata":{}},{"cell_type":"code","source":"# Data manipution packages. \nimport pandas as pd\nimport numpy as np\n\n# Data visualization packages.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# File manager packages.\nimport os\nimport shutil\n\n# Tensoflow packages.\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Flatten, Conv1D, MaxPooling1D, Bidirectional, LSTM, RNN, GRU, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential, Model\n\n# Other packages.\n%matplotlib inline","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-05-23T06:24:06.175116Z","iopub.execute_input":"2023-05-23T06:24:06.175603Z","iopub.status.idle":"2023-05-23T06:24:06.186969Z","shell.execute_reply.started":"2023-05-23T06:24:06.175563Z","shell.execute_reply":"2023-05-23T06:24:06.185353Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Data Collecion**\n---","metadata":{}},{"cell_type":"markdown","source":"For this project we will be working from the kaggle notebook,and since our data is already in our working station we would just be loading our dataset from the kaggle input directory. \n\nTo download this dataset from kaggle for colab and local system use, i will be providing commented code to help with this.","metadata":{}},{"cell_type":"markdown","source":"## Download kaggle dataset. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-23T06:23:47.115981Z","iopub.status.idle":"2023-05-23T06:23:47.116526Z","shell.execute_reply.started":"2023-05-23T06:23:47.116257Z","shell.execute_reply":"2023-05-23T06:23:47.116299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}